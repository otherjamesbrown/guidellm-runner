# Staging environment values for guidellm-runner

image:
  repository: ghcr.io/otherjamesbrown/ai-aas/guidellm-runner
  tag: "dev"
  pullPolicy: Always
  pullSecrets:
    - ghcr-pull-secret

# Use dedicated API key secret for benchmarking
apiKey:
  existingSecret: "guidellm-runner-api-key"
  existingSecretKey: "api-key"

config:
  logLevel: info

  defaults:
    profile: constant
    rate: 1
    interval: 300  # Run benchmark every 5 minutes
    maxSeconds: 60
    maxTokens: 100
    # Use emulated data with gpt2 tokenizer for text_completions
    dataSpec: "type=emulated,tokenizer=gpt2,prompt_tokens=256,output_tokens=128"

  environments:
    staging:
      targets:
        - name: unsloth-gpt-oss-20b
          # Use internal cluster DNS for better reliability
          url: http://api-router-service-staging-api-router-service.staging.svc.cluster.local:8080
          model: unsloth/gpt-oss-20b
          rate: 1
          maxSeconds: 60
        - name: openai-gpt-oss-20b
          url: http://api-router-service-staging-api-router-service.staging.svc.cluster.local:8080
          model: openai/gpt-oss-20b
          rate: 1
          maxSeconds: 60
        - name: mistral-7b
          url: http://api-router-service-staging-api-router-service.staging.svc.cluster.local:8080
          model: mistralai/Mistral-7B-Instruct-v0.3
          rate: 1
          maxSeconds: 60

resources:
  limits:
    cpu: "2"
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 2Gi

serviceMonitor:
  enabled: true
  interval: 15s
  labels:
    release: kube-prometheus-stack

# Prefer CPU nodes (avoid GPU nodes)
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: lke.linode.com/pool-id
              operator: NotIn
              values:
                - "785977"  # GPU node pool
                - "785978"  # GPU node pool
