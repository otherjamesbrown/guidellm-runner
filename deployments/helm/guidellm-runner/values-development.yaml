# Development environment values for guidellm-runner

image:
  repository: ghcr.io/otherjamesbrown/ai-aas/guidellm-runner
  tag: "dev"
  pullPolicy: Always
  pullSecrets:
    - ghcr-pull-secret

# Use existing secret for API key
apiKey:
  existingSecret: "guidellm-runner-api-key"
  existingSecretKey: "api-key"

config:
  logLevel: info

  defaults:
    profile: constant
    rate: 1
    interval: 300  # Run benchmark every 5 minutes
    maxSeconds: 60
    maxTokens: 100
    # Use emulated data with gpt2 tokenizer for text_completions
    # (synthetic format needs model-specific tokenizer which may not be available)
    dataSpec: "type=emulated,tokenizer=gpt2,prompt_tokens=256,output_tokens=128"

  # NOTE: Model IDs must match /v1/models endpoint, not HuggingFace IDs
  # Run: curl -s https://api.dev.otherjamesbrown.com/v1/models | jq '.data[].id'
  # TODO: aas-yirci - Auto-discover models from /v1/models endpoint
  environments:
    development:
      targets:
        - name: unsloth-gpt-oss-20b
          url: https://api.dev.otherjamesbrown.com
          model: unsloth-gpt-oss-20b
          rate: 1
          maxSeconds: 60
        - name: llama-3-1-8b-instruct-vllm
          url: https://api.dev.otherjamesbrown.com
          model: llama-3-1-8b-instruct-vllm
          rate: 1
          maxSeconds: 60
        - name: llama-3-1-8b-instruct-trtllm
          url: https://api.dev.otherjamesbrown.com
          model: llama-3-1-8b-instruct-trtllm
          rate: 1
          maxSeconds: 60

resources:
  limits:
    cpu: "2"
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 2Gi

serviceMonitor:
  enabled: true
  interval: 15s
  labels:
    release: kube-prometheus-stack

# Prefer CPU nodes (avoid GPU nodes)
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: lke.linode.com/pool-id
              operator: In
              values:
                - "770211"  # CPU node pool
